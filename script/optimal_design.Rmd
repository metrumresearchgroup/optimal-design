---
title: "Optimal Design for PK/PD"
order: 99
tags: ["science-resources", "optimal design", "poped"]
output: 
  github_document:
    toc: true
    toc_depth: 5
---

TODO

* more detail about create.poped.database
* mrgsolve mode: something more complex, like M-M CL
* SSE for examples


```{r, include = FALSE}
knitr:::opts_chunk$set(comment = '.', message = FALSE, warning = FALSE)
```

This document gives a brief background on optimal design of experiments and how it can be applied to studies involving PK/PD models.  We give an example of PK sampling time selection using the R package [`PopED`](https://cran.r-project.org/web/packages/PopED/index.html).  If you don't care about how this works (although you probably should), you can skip the background.

# Optimal design background

PK/PD studies should be designed in such a way that model parameters can be estimated with adequate precision and bias.  This can be assessed by simulation, but depending on the study and model(s) involved, it can be impractical to evaluate many combinations of design variables.  Optimal design tools allow us to quickly (however approximately) evaluate designs, and even search over a design space for the best possible design.

## Fisher information matrix

As the name implies, optimal designs are experimental designs that are optimal with respect to some criterion.  Many such criteria exist, but most involve the [Fisher information matrix](https://en.wikipedia.org/wiki/Fisher_information) (FIM).  This matrix is useful because it gives us a [lower bound](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound) on the covariance matrix of our parameter estimates.

The most commonly used criterion is the *D*-optimalilty criterion.  *D*-optimal designs maximize the determinant of the FIM, which is equivalent to minimizing the (lower bound of) the determinant of the covariance matrix of the parameter estimates.  For a single parameter, this means we're minimizing the width of its confidence interval, estimating it as precisely as possible.  Extending this to multiple parameters, we're minimizing the volume of the confidence ellipsoid, which loosely translates to maximizing the overall precision of parameter estimates.

The FIM is typically notated by something like *M*<sub>*F*</sub>(&Phi;,&Xi;), where &Phi; is the vector of parameter values (e.g. *CL*, &omega;<sub>*CL*</sub>, etc.) and &Xi; is the vector of design variables (e.g. dose levels, PK sampling times, etc.).  For linear models, the dependence on the parameters disappears.  Unfortunately for us, this is not the case for nonlinear models.  So in order to design our experiment in a way that will produce the best parameter estimates, we first need to know the values of those parameters.  This is the catch-22 of optimal design.  The good news is that we usually have *some* sense of parameter values from earlier clinical trials or even predictions from animal data.  We can even incorporate uncertainty of the estimates (e.g. with *ED*- or *HC*ln*D*-optimality).

## Nonlinear mixed effects models

More often than not, we're dealing with nonlinear mixed effects (NLME) models.  Since the FIM depends on the likelihood function, and there is sadly no analytic expression for the likelihood in NLME models, we must rely on approximations.  See Mentre1997-ds, Retout2001-lw, and Retout2003-jx for FIM approximations available to us.

So our FIM is

* an approximation
* to a lower bound
* that depends on the parameter values.

How useful could that even be?  Pretty useful, actually.  In most cases you'll probably find that you have adequate information on parameter estimates and that these approximate lower bounds aren't too far off what you'll get from simulations.

Either way, I **strongly** recommend that any optimal design exercise is capped off with confirmatory simulations using the tool (e.g. NONMEM) that you'll be using in the actual analysis of the data.

## Evaluation vs Optimization

Optimal design tools can be used in the way that the name implies (to actually optimize a study), or we can simply evaluate a design with a quick calculation of the FIM (and a translation of the FIM to expected relative standard errors).  Optimization is usually a "last resort", and most of the time you'll only need to evaluate a few potential designs before settling on the answer.

That's not to say that optimization doesn't have its place.  For example, resources may be very tightly constrained, or intuitive selection of potential doses or sampling times doesn't produce sufficient results.  In these cases, we'd use a search algorithm to determine an optimal design.

## Sampling windows

A common application of optimal design is the selection of PK sampling times.  In practice, we often can't practically collect PK samples at precise times.  Also, optimization of sampling times will usually tell you to collect samples at seemingly bizarre times like 3.4756 hours.  Or worse, it may require *multiple* samples at the same time (if you can't specify a minimum period between samples).  In these cases, we can specify windows of time for each collection.

Although methods exist for optimal determination of the windows, you will mostly likely be able to do a perfectly good job yourself by picking these manually.  You can then determine the suitability of the windows by seeing how uniform sampling within the windows impacts relative standard errors (both in optimal design tools like `PopED` or in your simulation).


# Packages and setup

```{r message=FALSE}
requireNamespace("metrumrg")
library(tidyverse)
library(mrgsolve)
library(PopED)
```

# Introducing our example

Mockdrozaline has been studied in adult subjects, and we now must design a study in pediatric patients.  The primary objective is to evaluate the PK in this new population, but PK sampling is necessarily sparse.  Our mission is to ensure that these samples are timed such that we can sufficiently estimate the PK parameters in pediatric patients.

## The study

Population

* 24 subjects
* Aged 6 to < 12
* Expected median weight of 32 kg

Treatment

* 10 mg QD mockdrozaline for 24 weeks

PK samples

* Proposed samples:
  - 5 hours postdose on Day 1;
  - predose on Weeks 8, 12, 24; and
  - 168 hours after the final dose

## The model

A wealth of data in adults has allowed us to describe orally-administered mockdrozaline PK using a 1-compartment model with first-order absorption, and 2 covariates: weight on clearance (`wt_cl`) and weight on volume (`wt_v`).

```{r echo=FALSE}
tibble(
  CL = 10, V = 100, KA = 0.25,
  wt_cl = 0.75, wt_v = 1
) %>% 
  knitr::kable()
```

```{r}
pk <- function(time, n, tau = 24) {
  DOSE <- 10*1000
  WT <- 32
  CL <- 10 * (WT/70)^0.75
  V <- 100 * (WT/70)
  KA <- 0.25
  
  y <- rep(0, length(time))
  for (i in 1:n) {
    sel <- (time >= (tau * (i - 1)))
    time_n <- time[sel] - (tau * (i - 1))
    y[sel] <- y[sel] + (DOSE * KA/(V * (KA - CL/V))) *
      (exp(-CL/V * time_n) - exp(-KA * time_n))
  }
  return(y)
}
time <- seq(0, 168, by = 0.2)
tibble(
  time = seq(0, 168, by = 0.2),
  conc = pk(time, n = 7)
) %>% 
  ggplot(aes(time, conc)) +
  geom_line() +
  theme_bw() +
  labs(x = "Time (hours)", y = "Concentration (ng/mL)")
```

We clearly reach steady state very quickly.

We include log-normal IIV on `CL`, `V`, and `KA`, and a combined additive and proportional residual error.

```{r echo=FALSE}
tibble(
  om_CL = 0.08, om_V = 0.1, om_KA = 0.2, sigma_prop = 0.05, sigma_add = 1
) %>% 
  knitr::kable()
```

Note that we reach steady state very quickly, so we can assume that all samples after Day 1 (i.e. from Week 4 onward) are at steady state.

# The `PopED` setup

`PopED` requires 3 functions in order to define a model:

* `ff()`, the structural model;
* `fg()`, the parameter model (including IIV and IOV);
* `feps()`, the residual error model.

(The names of the functions can be different, but these are the naming conventions used by `PopED`.)  There are built-in `ff()` and `feps()` functions for basic structural models with additive and/or proportional residual error, but you'll need to at least write your own `fg()` function (don't worry, there are examples to get you started).

## `ff()`

The structural model is defined by the `mrgsolve` model, but we need to wrap it in a function that `PopED` can use.  `PopED` expects a function with the following arguments:

* `model_switch`: A vector of values, the same size as `xt`, identifying which model response should be computed for the corresponding `xt` value (e.g., for models with PK and PD responses).
* `xt`: A vector of independent variable values (often time).
* `parameters`: A named list of parameter values.
* `poped.db`: A `PopED` database. This can be used to extract information that may be needed in the model file.

We use a single dose at time 0 and a steady-state dose at 24 hours.  We do this to simplify the design: anything on Day 1 will be evaluated between 0 and 24 hours; and anything past Day 1 (at steady state) will be evaluated after 24 hours.

```{r}
ff <- function(model_switch, xt, parameters, poped.db){
  with(as.list(parameters),{
    
    CL <- CL*(WT/70)^(WT_CL)
    V <- V*(WT/70)^(WT_V)
    
    xt_sd <- xt[xt <= 24]
    xt_ss <- xt[xt > 24]
    xt_ss <- xt_ss - 24
    
    y_sd <- (DOSE * KA/(V * (KA - CL/V))) *
      (exp(-CL/V * xt_sd) - exp(-KA * xt_sd))
    
    y_ss <- (DOSE * KA/(V * (KA - CL/V))) *
      (exp(-CL/V * xt_ss) / (1 - exp(-CL/V * TAU)) -
         exp(-KA * xt_ss) / (1 - exp(-KA * TAU)))
      
    return(list(y = c(y_sd, y_ss), poped.db = poped.db))
  })
}
```

## `fg()`

Next is the parameter model, where we add IIV and/or IOV.  Again, there are several arguments that `PopED` expects:

* `x`: A vector of discrete design variables (not used here).
* `a`: A vector of covariates. Note that dose and dosing interval are also passed in as covariates, in addition to what we'd normally classify as covariates in a PK/PD model.
* `bpop`: A vector of fixed effect parameters (i.e., `THETA`s).
* `b`: A vector of individual IIV random effects (i.e., `ETA`s).
* `bocc`: A vector of individual IOV random effects (i.e., `ETA`s) (not used here).

In this example, we include IIV on `CL`, `V`, and `KA`, and pass through dose, tau, and body weight as covariates.

```{r}
fg <- function(x, a, bpop, b, bocc){
  parameters = c(
    CL    = bpop[1] * exp(b[1]),
    V     = bpop[2] * exp(b[2]),
    KA    = bpop[3] * exp(b[3]),
    WT_CL = bpop[4],
    WT_V  = bpop[5],
    DOSE  = a[1] * 1000,
    TAU   = a[2],
    WT    = a[3]
  )
  return(parameters) 
}
```

## `feps()`

Final, we define the residual error model structure.  We're using a log-normal residual error model (i.e., additive on the log scale), so we need to define a custom function for this as well.  The setup is a bit esoteric, so we just start with one of the built-in functions and tweak as necessary.  There's only one new argument here:

* `epsi`: A matrix of residual random effects (i.e. `EPS`s or `ERR`s).

```{r}
feps <- function(model_switch, xt, parameters, epsi, poped.db){
  returnArgs <- do.call(
    poped.db$model$ff_pointer,
    list(model_switch, xt, parameters, poped.db)
  ) 
  y <- returnArgs[[1]]
  poped.db <- returnArgs[[2]]
  y = y * exp(epsi[, 1])
  return(list(y = y, poped.db = poped.db)) 
}
```

## `create.poped.database()`

Now that we have our model defined, we bring it all together with details of the design.  There's a lot going on here even for this simple example (the documentation is 13 pages long for this function alone), so we'll break this down into pieces.

```{r}
poped_db <- create.poped.database(
  ff_fun = ff,
  fg_fun = fg,
  #fError_fun = feps,
  fError_fun = feps.add.prop,
  bpop = c(CL = 10, V = 100, KA = 0.25, WT_CL = 0.75, WT_V = 1), 
  notfixed_bpop = c(1, 1, 1, 0, 0),
  d = c(CL = 0.08, V = 0.1, KA = 0.2), 
  #sigma = c(0.05),
  #notfixed_sigma = c(1),
  sigma = c(0.05, 1),
  notfixed_sigma = c(1, 1),
  m = 1,
  groupsize = 12,
  xt = c(5, c(rep(24, 3), 168) + 24),
  minxt = c(0, c(rep(23, 3), 96) + 24),
  maxxt = c(6, c(rep(24, 3), 168) + 24),
  bUseGrouped_xt = 0,
  a = cbind(DOSE = 10, TAU = 24, WT = 32)
)
```

We've covered the functions used in the first 3 arguments.  Let's break down the rest.

```{r eval=FALSE}
  bpop = c(CL = 10, V2 = 100, Q = 1, V3 = 30, KA = 0.25), 
```



```{r eval=FALSE}
  notfixed_bpop = c(1, 1, 1, 1, 1),
```



```{r eval=FALSE}
  d = c(CL = 0.08, V2 = 0.1), 
```



```{r eval=FALSE}
  sigma = c(0.05),
```



```{r eval=FALSE}
  notfixed_sigma = c(1),
```



```{r eval=FALSE}
  m = 1,
  groupsize = 36,
```



```{r eval=FALSE}
  xt = c(5, c(rep(24, 6), 168) + 24),
```



```{r eval=FALSE}
  minxt = c(0, c(rep(24, 6), 168) + 24 - 1),
  maxxt = c(6, c(rep(24, 6), 168) + 24),
```



```{r eval=FALSE}
  bUseGrouped_xt = 0,
```



```{r eval=FALSE}
  a = cbind(DOSE = 10, TAU = 24, WT = 32)
```

## Test plot

`PopED` includes a function to generate a quick test plot showing the typical response(s), along with the initial sampling times.  We'll tweak the output a bit to show the separate responses for Day 1 and steady state.

```{r}
p <- plot_model_prediction(poped_db, model_num_points = 200) +
  labs(x = "Time from dose (h)") +
  theme_bw()
p +
  xlim(0, 24) +
  scale_x_continuous(
    lim = c(0, 24),
    breaks = seq(0, 24, by = 6)
  ) +
  ggtitle("Day 1")
p +
  scale_x_continuous(
    lim = c(0, 168) + 24,
    breaks = seq(0, 168, by = 24) + 24,
    labels = seq(0, 168, by = 24)
  ) +
  ggtitle("Steady state")
```

# Evaluate FIM

```{r}
FIM <- evaluate.fim(poped_db) 
det(FIM)
```

This determinant is what will be used to optimize the design, but it's not particularly helpful by itself.  What we really need are the predicted standard errors based on the FIM.

```{r}
get_rse(FIM, poped_db)
```

The RSEs are looking pretty good, but let's see if we can make any improvements with optimization.

# *D*-optimal design

## Starting from the original design

```{r optimal,eval=FALSE}
output <- poped_optim(
  poped_db,
  opt_xt = TRUE,
  parallel = TRUE,
  parallel_type = "multicore",
  seed = 1
)
saveRDS(output, "opt1.rds")
```

```{r}
output <- readRDS("opt1.rds")
summary(output)
```

## Adding another post dose sample at steady state

Add another post dose sample at steady state.

We'll create the PopED database from scratch again.  This is probably easier than updating an old database when you change the number of samples because certain vectors (like `model_switch`) get calculated automatically if you don't supply the argument and we don't want to fuss with that.

```{r}
poped_db_extra_ss <- create.poped.database(
  ff_fun = ff,
  fg_fun = fg,
  #fError_fun = feps,
  fError_fun = feps.add.prop,
  bpop = c(CL = 10, V = 100, KA = 0.25, WT_CL = 0.75, WT_V = 1), 
  notfixed_bpop = c(1, 1, 1, 0, 0),
  d = c(CL = 0.08, V = 0.1, KA = 0.2), 
  #sigma = c(0.05),
  #notfixed_sigma = c(1),
  sigma = c(0.05, 1),
  notfixed_sigma = c(1, 1),
  m = 1,
  groupsize = 12,
  xt = c(5, c(rep(24, 3), 4, 168) + 24),
  minxt = c(0, c(rep(23, 3), 0, 96) + 24),
  maxxt = c(6, c(rep(24, 3), 6, 168) + 24),
  bUseGrouped_xt = 0,
  a = cbind(DOSE = 10, TAU = 24, WT = 32)
)
```

```{r}
FIM_extra_ss <- evaluate.fim(poped_db_extra_ss) 
get_rse(FIM_extra_ss, poped_db_extra_ss)
```

```{r optimal_extra_ss,eval=FALSE}
output_extra_ss <- poped_optim(
  poped_db_extra_ss,
  opt_xt = TRUE,
  parallel = TRUE,
  parallel_type = "multicore",
  seed = 1
)
saveRDS(output_extra_ss, "opt2.rds")
```

```{r}
output_extra_ss <- readRDS("opt2.rds")
summary(output_extra_ss)
```

## Adding sample after the final (steady-state) dose

Add another sample after the final dose.

We'll create the PopED database from scratch again.

```{r}
poped_db_final <- create.poped.database(
  ff_fun = ff,
  fg_fun = fg,
  #fError_fun = feps,
  fError_fun = feps.add.prop,
  bpop = c(CL = 10, V = 100, KA = 0.25, WT_CL = 0.75, WT_V = 1), 
  notfixed_bpop = c(1, 1, 1, 0, 0),
  d = c(CL = 0.08, V = 0.1, KA = 0.2), 
  #sigma = c(0.05),
  #notfixed_sigma = c(1),
  sigma = c(0.05, 1),
  notfixed_sigma = c(1, 1),
  m = 1,
  groupsize = 24,
  xt = c(5, c(rep(24, 3), 72, 168) + 24),
  minxt = c(0, c(rep(23, 3), 0, 168) + 24),
  maxxt = c(6, c(rep(24, 3), 168, 168) + 24),
  bUseGrouped_xt = 0,
  a = cbind(DOSE = 10, TAU = 24, WT = 32)
)
```

```{r}
FIM_final <- evaluate.fim(poped_db_final) 
get_rse(FIM_final, poped_db_final)
```

```{r optimal_final,eval=FALSE}
output_final <- poped_optim(
  poped_db_final,
  opt_xt = TRUE,
  parallel = TRUE,
  parallel_type = "multicore",
  seed = 1
)
saveRDS(output_final, "opt3.rds")
```

```{r}
output_final <- readRDS("opt3.rds")
summary(output_final)
```

# Near-optimal design

This optimal design serves us well, but it's not very practical to request a sample at 65.09 hours (actually 41.09 hours after the final dose).  For a dose at 8 AM, that would mean a sample at around 1 AM.  Instead we'll construct a similar design with more practical times and see how that affects our RSEs.  We can do this by building a new `PopED` database based on the previous one.

```{r}
poped_db_practical <- create.poped.database(
  poped_db_final,
  xt = c(0.5, rep(48, 3), 56, 192)
)
FIM_practical <- evaluate.fim(poped_db_practical) 
get_rse(FIM_practical, poped_db_practical)
p <- plot_model_prediction(poped_db_practical, model_num_points = 200) +
  labs(x = "Time from dose (h)") +
  theme_bw()
p +
  xlim(0, 24) +
  scale_x_continuous(
    lim = c(0, 24),
    breaks = seq(0, 24, by = 6)
  ) +
  ggtitle("Day 1")
p +
  scale_x_continuous(
    lim = c(0, 168) + 24,
    breaks = seq(0, 168, by = 24) + 24,
    labels = seq(0, 168, by = 24)
  ) +
  ggtitle("Steady state")
```

This second-to-last sample at "56" hours is actually 32 hours after the final dose, based on the way we've set up the steady-state model.  For an 8 AM dose, this would mean a sample taken at 4 PM the following day.  More practical, and we don't seem to lose too much in terms of RSE.

# Sampling windows

Next, we'll construct windows around our sampling times to provide some flexibility in sampling.  We evaluate the effect of this flexibility on the RSEs.

We'll allow:

* up to 15 minutes before or after the first sample at half an hour (i.e., 15-45 minutes post dose)
* up to 1 hour before each trough sample (i.e., 0-1 hours pre dose)
* up to 2 hours before or after the 32-hour sample after the final dose (i.e., 30-34 hours after the final dose)
* up to 4 hours before the final sample (i.e., 164-168 hours post final dose)

```{r}
plot_efficiency_of_windows(
  poped_db_practical,
  xt_plus  = c(0.25, rep(0, 3), 2, 0),
  xt_minus = c(0.25, rep(1, 3), 2, 4)
)
```

The 100 sets of simulated samples show no significant deviations from the RSEs for the optimal samples.

```{r}
#
## `mrgsolve`
#
#Here is the model in `mrgsolve`.  Note that this includes no variability yet.  The reason for this will become apparently once we start incorporating the `PopED` functions.
#
#```{r}
#mod <- mread(file.path("model", "model_poped"))
#see(mod)
#```
#
### `ff()`
#
#The structural model is defined by the `mrgsolve` model, but we need to wrap it in a function that `PopED` can use.
#
#We use `mrgsim_q()` to get the simulation turned around as quickly as
#possible, reducing overhead (and dropping features).  We use a single dose at time 0 and a steady-state dose at 24 hours.  We do this to simplify the design: anything on Day 1 will be evaluated between 0 and 24 hours; and anything past Day 1 (at steady state) will be evaluated after 24 hours.
#
#```{r}
#ff <- function(model_switch, xt, parameters, poped.db){
#  times_xt <- drop(xt)  
#  dose_times <- c(0, 24)
#  time <- sort(unique(c(times_xt, dose_times)))
#  is.dose <- time %in% dose_times
#
#  data <- data.frame(
#    ID = 1,
#    time = time,
#    amt = ifelse(is.dose, parameters[["DOSE"]] * 1000, 0), 
#    cmt = ifelse(is.dose, 1, 0),
#    ss = ifelse(time == 24, 1, 0),
#    ii = ifelse(time == 24, 24, 0)
#  )
#
#  data[["evid"]] <- data[["cmt"]]
#
#  out <- mod %>% 
#    param(as.list(parameters)) %>% 
#    mrgsim_q(data, recsort = 4)
#
#  y <- out$CP[match(times_xt, out$time)]
#
#  return(list(y = matrix(y, ncol = 1), poped.db = poped.db))
#}
#```
```

# Other resources

* `PopED` vignette: [Introduction to `PopED`](https://cran.r-project.org/web/packages/PopED/vignettes/intro-poped.html)
* `PopED` vignette: [Examples](https://cran.r-project.org/web/packages/PopED/vignettes/intro-poped.html)
* mrgsolve wiki: [`PopED` vignette](https://github.com/metrumresearchgroup/mrgsolve/wiki/PopED_vignette)